{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab727787",
   "metadata": {},
   "source": [
    "https://github.com/santino-iannone/PytorchDenoisingAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09fa4ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7623f971d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from PIL import Image\n",
    "import glob\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from torchvision.models import vgg19\n",
    "\n",
    "# 코드 실행결과의 동일성을 위해 무작위 시드를 설정합니다\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # 만일 새로운 결과를 원한다면 주석을 없애면 됩니다\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61de6bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ef242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/user303/GAN/COVID-19_Radiography_Dataset/Normal/images'\n",
    "image_paths = glob.glob(path + '/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8378c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "import cv2\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, transform=None):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.paths[index]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "        \n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image)\n",
    "            \n",
    "        return image_tensor\n",
    "    \n",
    "train_dataset = ImageDataset(image_paths[:round(len(image_paths)*0.8)], transform)\n",
    "test_dataset = ImageDataset(image_paths[round(len(image_paths)*0.8):], transform) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8440ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "data_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b21317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0078, 0.0000, 0.0000,  ..., 0.1569, 0.2157, 0.3608],\n",
      "          [0.0039, 0.0000, 0.0000,  ..., 0.0078, 0.0353, 0.1686],\n",
      "          [0.0039, 0.0000, 0.0000,  ..., 0.0000, 0.0157, 0.1412],\n",
      "          ...,\n",
      "          [0.2941, 0.2039, 0.0471,  ..., 0.4118, 0.5686, 0.6902],\n",
      "          [0.3098, 0.2353, 0.0627,  ..., 0.4235, 0.5765, 0.6980],\n",
      "          [0.3451, 0.2824, 0.1216,  ..., 0.4314, 0.5882, 0.7020]]]])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64b455e",
   "metadata": {},
   "source": [
    "### 모형 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e13ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "def add_noise(noise_typ,image):\n",
    "    #Gaussian Noisy\n",
    "    if noise_typ == \"gauss\":\n",
    "        image = np.array(image)\n",
    "        noisy = image + 0.1 *  np.random.normal(loc=0,scale=1.,size=image.shape)\n",
    "        noisy = torch.Tensor(noisy)\n",
    "        return noisy\n",
    "\n",
    "    #Salt & Pepper Noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        bt,ch,row,col= image.shape\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.05\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * 4096 * s_vs_p)\n",
    "        print(num_salt)\n",
    "        coords = [np.random.randint(0,i,3) for i in image.shape[1:]]\n",
    "        print(coords)\n",
    "        out[tuple(coords)] = 1\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount * 4096 * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i ,3) for i in image.shape[1:]]\n",
    "        out[tuple(coords)] = 0\n",
    "        out = torch.Tensor(out)\n",
    "        return out\n",
    "\n",
    "    # Speckle Noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        noisy = np.random.normal(loc=0,scale=1.,size=image.shape)\n",
    "        noisy = image+ image * 0.1 *noisy\n",
    "        noisy = torch.Tensor(noisy)\n",
    "        return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a3cb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "# A small denoising autoencoder model with 0.25 of input data dropped\n",
    "class DenoisingAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoisingAE, self).__init__()\n",
    "        self.add_noise = add_noise\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(64*64, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3),\n",
    "        )\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(3, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, 64*64)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.add_noise(\"gauss\",x.cpu()).to(device)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        x = x.view(-1,1,64,64)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d008809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [1, 4096]               0\n",
      "            Linear-2                   [1, 250]       1,024,250\n",
      "              ReLU-3                   [1, 250]               0\n",
      "            Linear-4                    [1, 50]          12,550\n",
      "              ReLU-5                    [1, 50]               0\n",
      "            Linear-6                     [1, 3]             153\n",
      "            Linear-7                    [1, 50]             200\n",
      "              ReLU-8                    [1, 50]               0\n",
      "            Linear-9                   [1, 250]          12,750\n",
      "             ReLU-10                   [1, 250]               0\n",
      "           Linear-11                  [1, 4096]       1,028,096\n",
      "================================================================\n",
      "Total params: 2,077,999\n",
      "Trainable params: 2,077,999\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.07\n",
      "Params size (MB): 7.93\n",
      "Estimated Total Size (MB): 8.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = DenoisingAE().to(device)\n",
    "\n",
    "summary(model, (1,64,64), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb64037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.00001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1018cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "mae_loss = nn.L1Loss()\n",
    "start_time = time.time()\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    train_psnr = 0\n",
    "    train_mae = 0\n",
    "    for batch, x in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        model.train()\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, x)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_psnr += PSNR(pred,x)\n",
    "        train_mae += mae_loss(pred,x)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= num_batches\n",
    "    train_psnr /= num_batches\n",
    "    train_mae /= num_batches     \n",
    "        \n",
    "    print(\"\\nLOSS: {:.8f}, TIME: {:.1f}s, psnr : {:1f}, mae : {:1f}\".format(train_loss, \n",
    "      time.time() - start_time,train_psnr,train_mae))\n",
    "\n",
    "        # if batch % 100 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdc6c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def PSNR(img1, img2, min_value=0, max_value=1):\n",
    "    \"\"\"\n",
    "    psnr 을 계산해준다.\n",
    "    이미지가 [0., 255] 이면 min_value=0, max_valu=255 로 해주고,\n",
    "    이미지가 [-1,1]의 범위에 있으면 min_value=-1, max_valu=1 로 설정 해준다.\n",
    "    \"\"\"\n",
    "    if type(img1) == torch.Tensor:\n",
    "        mse = torch.mean((img1 - img2) ** 2)\n",
    "    else:\n",
    "        mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = max_value - min_value\n",
    "    return 10 * math.log10((PIXEL_MAX ** 2) / mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fa6d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model accuracy on one batch\n",
    "start_time = time.time()\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_psnr = 0\n",
    "    test_mae = 0\n",
    "    with torch.no_grad():\n",
    "        for x in dataloader:\n",
    "            x = x.to(device)\n",
    "            pred = model(x)\n",
    "            test_loss += loss_fn(pred,x).item()\n",
    "            test_psnr += PSNR(pred,x)\n",
    "            test_mae += mae_loss(pred,x)\n",
    "    test_loss /= num_batches\n",
    "    test_psnr /= num_batches\n",
    "    test_mae /= num_batches\n",
    "    print(\"\\nLOSS: {:.8f}, TIME: {:.1f}s, psnr : {:1f}, mae : {:1f}\".format(test_loss, \n",
    "      time.time() - start_time,test_psnr,test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e9307d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n",
      "LOSS: 0.01497662, TIME: 45.4s, psnr : 18.710699, mae : 0.089931\n",
      "Epoch 2\n",
      "\n",
      "LOSS: 0.01463105, TIME: 90.6s, psnr : 18.814458, mae : 0.088637\n",
      "Epoch 3\n",
      "\n",
      "LOSS: 0.01442424, TIME: 135.9s, psnr : 18.876256, mae : 0.087923\n",
      "Epoch 4\n",
      "\n",
      "LOSS: 0.01432443, TIME: 181.2s, psnr : 18.906168, mae : 0.087572\n",
      "Epoch 5\n",
      "\n",
      "LOSS: 0.01429093, TIME: 226.5s, psnr : 18.919675, mae : 0.087416\n",
      "Epoch 6\n",
      "\n",
      "LOSS: 0.01426291, TIME: 271.7s, psnr : 18.927735, mae : 0.087330\n",
      "Epoch 7\n",
      "\n",
      "LOSS: 0.01423557, TIME: 317.0s, psnr : 18.938104, mae : 0.087211\n",
      "Epoch 8\n",
      "\n",
      "LOSS: 0.01423210, TIME: 362.3s, psnr : 18.939266, mae : 0.087203\n",
      "Epoch 9\n",
      "\n",
      "LOSS: 0.01420266, TIME: 407.6s, psnr : 18.948639, mae : 0.087090\n",
      "Epoch 10\n",
      "\n",
      "LOSS: 0.01418025, TIME: 452.9s, psnr : 18.954197, mae : 0.087050\n",
      "Epoch 11\n",
      "\n",
      "LOSS: 0.01417009, TIME: 497.6s, psnr : 18.959353, mae : 0.086982\n",
      "Epoch 12\n",
      "\n",
      "LOSS: 0.01415855, TIME: 542.4s, psnr : 18.962905, mae : 0.086959\n",
      "Epoch 13\n",
      "\n",
      "LOSS: 0.01414949, TIME: 587.6s, psnr : 18.968078, mae : 0.086912\n",
      "Epoch 14\n",
      "\n",
      "LOSS: 0.01413725, TIME: 633.0s, psnr : 18.970031, mae : 0.086878\n",
      "Epoch 15\n",
      "\n",
      "LOSS: 0.01413746, TIME: 678.1s, psnr : 18.972972, mae : 0.086837\n",
      "Epoch 16\n",
      "\n",
      "LOSS: 0.01412371, TIME: 723.3s, psnr : 18.978076, mae : 0.086787\n",
      "Epoch 17\n",
      "\n",
      "LOSS: 0.01409701, TIME: 768.6s, psnr : 18.984201, mae : 0.086744\n",
      "Epoch 18\n",
      "\n",
      "LOSS: 0.01409256, TIME: 813.9s, psnr : 18.986961, mae : 0.086697\n",
      "Epoch 19\n",
      "\n",
      "LOSS: 0.01408355, TIME: 856.2s, psnr : 18.991179, mae : 0.086664\n",
      "Epoch 20\n",
      "\n",
      "LOSS: 0.01408342, TIME: 901.4s, psnr : 18.992024, mae : 0.086663\n",
      "Epoch 21\n",
      "\n",
      "LOSS: 0.01407123, TIME: 946.6s, psnr : 18.994365, mae : 0.086610\n",
      "Epoch 22\n",
      "\n",
      "LOSS: 0.01404579, TIME: 991.9s, psnr : 19.001310, mae : 0.086561\n",
      "Epoch 23\n",
      "\n",
      "LOSS: 0.01405073, TIME: 1037.1s, psnr : 19.000820, mae : 0.086574\n",
      "Epoch 24\n",
      "\n",
      "LOSS: 0.01403341, TIME: 1082.3s, psnr : 19.006941, mae : 0.086476\n",
      "Epoch 25\n",
      "\n",
      "LOSS: 0.01403714, TIME: 1127.6s, psnr : 19.007913, mae : 0.086475\n",
      "Epoch 26\n",
      "\n",
      "LOSS: 0.01401787, TIME: 1172.9s, psnr : 19.012001, mae : 0.086426\n",
      "Epoch 27\n",
      "\n",
      "LOSS: 0.01401249, TIME: 1218.1s, psnr : 19.015043, mae : 0.086383\n",
      "Epoch 28\n",
      "\n",
      "LOSS: 0.01400335, TIME: 1263.2s, psnr : 19.018057, mae : 0.086369\n",
      "Epoch 29\n",
      "\n",
      "LOSS: 0.01397928, TIME: 1308.5s, psnr : 19.023306, mae : 0.086309\n",
      "Epoch 30\n",
      "\n",
      "LOSS: 0.01397968, TIME: 1353.7s, psnr : 19.024747, mae : 0.086296\n",
      "Epoch 31\n",
      "\n",
      "LOSS: 0.01397872, TIME: 1399.0s, psnr : 19.026643, mae : 0.086302\n",
      "Epoch 32\n",
      "\n",
      "LOSS: 0.01395872, TIME: 1444.2s, psnr : 19.031276, mae : 0.086246\n",
      "Epoch 33\n",
      "\n",
      "LOSS: 0.01394846, TIME: 1489.5s, psnr : 19.035459, mae : 0.086212\n",
      "Epoch 34\n",
      "\n",
      "LOSS: 0.01395029, TIME: 1534.7s, psnr : 19.036705, mae : 0.086225\n",
      "Epoch 35\n",
      "\n",
      "LOSS: 0.01393799, TIME: 1579.9s, psnr : 19.040060, mae : 0.086152\n",
      "Epoch 36\n",
      "\n",
      "LOSS: 0.01392174, TIME: 1625.1s, psnr : 19.045073, mae : 0.086135\n",
      "Epoch 37\n",
      "\n",
      "LOSS: 0.01392479, TIME: 1670.5s, psnr : 19.046902, mae : 0.086107\n",
      "Epoch 38\n",
      "\n",
      "LOSS: 0.01389711, TIME: 1715.8s, psnr : 19.053640, mae : 0.086030\n",
      "Epoch 39\n",
      "\n",
      "LOSS: 0.01390508, TIME: 1761.0s, psnr : 19.052233, mae : 0.086063\n",
      "Epoch 40\n",
      "\n",
      "LOSS: 0.01389024, TIME: 1806.3s, psnr : 19.056154, mae : 0.085996\n",
      "Epoch 41\n",
      "\n",
      "LOSS: 0.01388382, TIME: 1851.6s, psnr : 19.058241, mae : 0.085984\n",
      "Epoch 42\n",
      "\n",
      "LOSS: 0.01389228, TIME: 1896.8s, psnr : 19.059121, mae : 0.085960\n",
      "Epoch 43\n",
      "\n",
      "LOSS: 0.01387805, TIME: 1942.0s, psnr : 19.061211, mae : 0.085927\n",
      "Epoch 44\n",
      "\n",
      "LOSS: 0.01387639, TIME: 1987.2s, psnr : 19.062448, mae : 0.085916\n",
      "Epoch 45\n",
      "\n",
      "LOSS: 0.01386842, TIME: 2032.5s, psnr : 19.066470, mae : 0.085866\n",
      "Epoch 46\n",
      "\n",
      "LOSS: 0.01385424, TIME: 2077.8s, psnr : 19.069569, mae : 0.085796\n",
      "Epoch 47\n",
      "\n",
      "LOSS: 0.01385049, TIME: 2123.1s, psnr : 19.070432, mae : 0.085828\n",
      "Epoch 48\n",
      "\n",
      "LOSS: 0.01385498, TIME: 2168.4s, psnr : 19.071585, mae : 0.085804\n",
      "Epoch 49\n",
      "\n",
      "LOSS: 0.01382270, TIME: 2213.6s, psnr : 19.080455, mae : 0.085706\n",
      "Epoch 50\n",
      "\n",
      "LOSS: 0.01381930, TIME: 2258.8s, psnr : 19.080021, mae : 0.085716\n",
      "Epoch 51\n",
      "\n",
      "LOSS: 0.01381068, TIME: 2304.1s, psnr : 19.084202, mae : 0.085680\n",
      "Epoch 52\n",
      "\n",
      "LOSS: 0.01379447, TIME: 2349.3s, psnr : 19.088812, mae : 0.085615\n",
      "Epoch 53\n",
      "\n",
      "LOSS: 0.01379901, TIME: 2394.6s, psnr : 19.087283, mae : 0.085656\n",
      "Epoch 54\n",
      "\n",
      "LOSS: 0.01379606, TIME: 2439.8s, psnr : 19.090642, mae : 0.085621\n",
      "Epoch 55\n",
      "\n",
      "LOSS: 0.01379325, TIME: 2485.0s, psnr : 19.090578, mae : 0.085580\n",
      "Epoch 56\n",
      "\n",
      "LOSS: 0.01378168, TIME: 2530.3s, psnr : 19.094069, mae : 0.085568\n",
      "Epoch 57\n",
      "\n",
      "LOSS: 0.01376860, TIME: 2575.5s, psnr : 19.098427, mae : 0.085536\n",
      "Epoch 58\n",
      "\n",
      "LOSS: 0.01376350, TIME: 2620.7s, psnr : 19.100025, mae : 0.085501\n",
      "Epoch 59\n",
      "\n",
      "LOSS: 0.01377063, TIME: 2665.9s, psnr : 19.097926, mae : 0.085521\n",
      "Epoch 60\n",
      "\n",
      "LOSS: 0.01375582, TIME: 2711.3s, psnr : 19.105196, mae : 0.085439\n",
      "Epoch 61\n",
      "\n",
      "LOSS: 0.01376424, TIME: 2756.5s, psnr : 19.102743, mae : 0.085485\n",
      "Epoch 62\n",
      "\n",
      "LOSS: 0.01374420, TIME: 2801.8s, psnr : 19.107783, mae : 0.085428\n",
      "Epoch 63\n",
      "\n",
      "LOSS: 0.01372712, TIME: 2847.0s, psnr : 19.111301, mae : 0.085370\n",
      "Epoch 64\n",
      "\n",
      "LOSS: 0.01373054, TIME: 2892.2s, psnr : 19.112072, mae : 0.085366\n",
      "Epoch 65\n",
      "\n",
      "LOSS: 0.01372871, TIME: 2937.5s, psnr : 19.112821, mae : 0.085343\n",
      "Epoch 66\n",
      "\n",
      "LOSS: 0.01371852, TIME: 2982.7s, psnr : 19.114261, mae : 0.085356\n",
      "Epoch 67\n",
      "\n",
      "LOSS: 0.01371209, TIME: 3028.0s, psnr : 19.117833, mae : 0.085310\n",
      "Epoch 68\n",
      "\n",
      "LOSS: 0.01371857, TIME: 3073.2s, psnr : 19.115475, mae : 0.085311\n",
      "Epoch 69\n",
      "\n",
      "LOSS: 0.01369698, TIME: 3118.4s, psnr : 19.122778, mae : 0.085251\n",
      "Epoch 70\n",
      "\n",
      "LOSS: 0.01369401, TIME: 3163.7s, psnr : 19.123028, mae : 0.085249\n",
      "Epoch 71\n",
      "\n",
      "LOSS: 0.01369765, TIME: 3209.0s, psnr : 19.122600, mae : 0.085245\n",
      "Epoch 72\n",
      "\n",
      "LOSS: 0.01369317, TIME: 3254.2s, psnr : 19.123578, mae : 0.085237\n",
      "Epoch 73\n",
      "\n",
      "LOSS: 0.01368517, TIME: 3299.4s, psnr : 19.127613, mae : 0.085204\n",
      "Epoch 74\n",
      "\n",
      "LOSS: 0.01367666, TIME: 3344.6s, psnr : 19.128493, mae : 0.085185\n",
      "Epoch 75\n",
      "\n",
      "LOSS: 0.01367526, TIME: 3389.9s, psnr : 19.129891, mae : 0.085162\n",
      "Epoch 76\n",
      "\n",
      "LOSS: 0.01367106, TIME: 3435.1s, psnr : 19.132739, mae : 0.085137\n",
      "Epoch 77\n",
      "\n",
      "LOSS: 0.01367338, TIME: 3480.4s, psnr : 19.131822, mae : 0.085160\n",
      "Epoch 78\n",
      "\n",
      "LOSS: 0.01367407, TIME: 3525.6s, psnr : 19.132016, mae : 0.085149\n",
      "Epoch 79\n",
      "\n",
      "LOSS: 0.01365634, TIME: 3570.9s, psnr : 19.135441, mae : 0.085103\n",
      "Epoch 80\n",
      "\n",
      "LOSS: 0.01365082, TIME: 3616.2s, psnr : 19.137826, mae : 0.085079\n",
      "Epoch 81\n",
      "\n",
      "LOSS: 0.01364981, TIME: 3661.5s, psnr : 19.139513, mae : 0.085062\n",
      "Epoch 82\n",
      "\n",
      "LOSS: 0.01364689, TIME: 3706.6s, psnr : 19.139479, mae : 0.085074\n",
      "Epoch 83\n",
      "\n",
      "LOSS: 0.01363381, TIME: 3752.0s, psnr : 19.142985, mae : 0.085032\n",
      "Epoch 84\n",
      "\n",
      "LOSS: 0.01364015, TIME: 3797.3s, psnr : 19.142190, mae : 0.085035\n",
      "Epoch 85\n",
      "\n",
      "LOSS: 0.01363530, TIME: 3842.4s, psnr : 19.144130, mae : 0.085012\n",
      "Epoch 86\n",
      "\n",
      "LOSS: 0.01363814, TIME: 3887.7s, psnr : 19.143292, mae : 0.085027\n",
      "Epoch 87\n",
      "\n",
      "LOSS: 0.01362820, TIME: 3932.9s, psnr : 19.146403, mae : 0.084993\n",
      "Epoch 88\n",
      "\n",
      "LOSS: 0.01362601, TIME: 3978.1s, psnr : 19.146978, mae : 0.084982\n",
      "Epoch 89\n",
      "\n",
      "LOSS: 0.01362881, TIME: 4023.3s, psnr : 19.149031, mae : 0.084971\n",
      "Epoch 90\n",
      "\n",
      "LOSS: 0.01362156, TIME: 4068.7s, psnr : 19.148852, mae : 0.084970\n",
      "Epoch 91\n",
      "\n",
      "LOSS: 0.01360992, TIME: 4114.0s, psnr : 19.151876, mae : 0.084921\n",
      "Epoch 92\n",
      "\n",
      "LOSS: 0.01360850, TIME: 4159.1s, psnr : 19.152631, mae : 0.084914\n",
      "Epoch 93\n",
      "\n",
      "LOSS: 0.01360146, TIME: 4204.4s, psnr : 19.154780, mae : 0.084909\n",
      "Epoch 94\n",
      "\n",
      "LOSS: 0.01360348, TIME: 4249.7s, psnr : 19.154242, mae : 0.084916\n",
      "Epoch 95\n",
      "\n",
      "LOSS: 0.01359948, TIME: 4294.9s, psnr : 19.155577, mae : 0.084888\n",
      "Epoch 96\n",
      "\n",
      "LOSS: 0.01360113, TIME: 4340.2s, psnr : 19.155637, mae : 0.084878\n",
      "Epoch 97\n",
      "\n",
      "LOSS: 0.01359934, TIME: 4385.4s, psnr : 19.157033, mae : 0.084878\n",
      "Epoch 98\n",
      "\n",
      "LOSS: 0.01359350, TIME: 4430.7s, psnr : 19.158995, mae : 0.084843\n",
      "Epoch 99\n",
      "\n",
      "LOSS: 0.01359090, TIME: 4476.0s, psnr : 19.158814, mae : 0.084853\n",
      "Epoch 100\n",
      "\n",
      "LOSS: 0.01359163, TIME: 4521.1s, psnr : 19.158790, mae : 0.084864\n",
      "Epoch 101\n",
      "\n",
      "LOSS: 0.01358042, TIME: 4566.2s, psnr : 19.162850, mae : 0.084796\n",
      "Epoch 102\n",
      "\n",
      "LOSS: 0.01357452, TIME: 4611.5s, psnr : 19.164332, mae : 0.084788\n",
      "Epoch 103\n",
      "\n",
      "LOSS: 0.01357373, TIME: 4656.7s, psnr : 19.165580, mae : 0.084800\n",
      "Epoch 104\n",
      "\n",
      "LOSS: 0.01356680, TIME: 4702.0s, psnr : 19.167186, mae : 0.084773\n",
      "Epoch 105\n",
      "\n",
      "LOSS: 0.01357017, TIME: 4747.3s, psnr : 19.165062, mae : 0.084781\n",
      "Epoch 106\n",
      "\n",
      "LOSS: 0.01355305, TIME: 4792.6s, psnr : 19.170446, mae : 0.084711\n",
      "Epoch 107\n",
      "\n",
      "LOSS: 0.01355881, TIME: 4837.7s, psnr : 19.168444, mae : 0.084739\n",
      "Epoch 108\n",
      "\n",
      "LOSS: 0.01354361, TIME: 4882.9s, psnr : 19.173585, mae : 0.084698\n",
      "Epoch 109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOSS: 0.01356163, TIME: 4928.2s, psnr : 19.168892, mae : 0.084752\n",
      "Epoch 110\n",
      "\n",
      "LOSS: 0.01356294, TIME: 4973.4s, psnr : 19.169109, mae : 0.084730\n",
      "Epoch 111\n",
      "\n",
      "LOSS: 0.01355167, TIME: 5018.7s, psnr : 19.171335, mae : 0.084712\n",
      "Epoch 112\n",
      "\n",
      "LOSS: 0.01354830, TIME: 5063.9s, psnr : 19.173581, mae : 0.084696\n",
      "Epoch 113\n",
      "\n",
      "LOSS: 0.01353520, TIME: 5109.2s, psnr : 19.177998, mae : 0.084634\n",
      "Epoch 114\n",
      "\n",
      "LOSS: 0.01352098, TIME: 5154.5s, psnr : 19.180957, mae : 0.084612\n",
      "Epoch 115\n",
      "\n",
      "LOSS: 0.01354325, TIME: 5199.8s, psnr : 19.175575, mae : 0.084693\n",
      "Epoch 116\n",
      "\n",
      "LOSS: 0.01353409, TIME: 5245.0s, psnr : 19.178893, mae : 0.084643\n",
      "Epoch 117\n",
      "\n",
      "LOSS: 0.01352737, TIME: 5290.2s, psnr : 19.180389, mae : 0.084622\n",
      "Epoch 118\n",
      "\n",
      "LOSS: 0.01352914, TIME: 5335.5s, psnr : 19.180261, mae : 0.084618\n",
      "Epoch 119\n",
      "\n",
      "LOSS: 0.01353803, TIME: 5380.7s, psnr : 19.178235, mae : 0.084667\n",
      "Epoch 120\n",
      "\n",
      "LOSS: 0.01353760, TIME: 5426.0s, psnr : 19.176514, mae : 0.084650\n",
      "Epoch 121\n",
      "\n",
      "LOSS: 0.01352128, TIME: 5471.3s, psnr : 19.182289, mae : 0.084570\n",
      "Epoch 122\n",
      "\n",
      "LOSS: 0.01352414, TIME: 5516.5s, psnr : 19.183732, mae : 0.084594\n",
      "Epoch 123\n",
      "\n",
      "LOSS: 0.01351813, TIME: 5561.8s, psnr : 19.185018, mae : 0.084583\n",
      "Epoch 124\n",
      "\n",
      "LOSS: 0.01350644, TIME: 5607.0s, psnr : 19.184994, mae : 0.084560\n",
      "Epoch 125\n",
      "\n",
      "LOSS: 0.01351164, TIME: 5652.3s, psnr : 19.187882, mae : 0.084534\n",
      "Epoch 126\n",
      "\n",
      "LOSS: 0.01350387, TIME: 5697.5s, psnr : 19.188086, mae : 0.084540\n",
      "Epoch 127\n",
      "\n",
      "LOSS: 0.01350480, TIME: 5742.6s, psnr : 19.187964, mae : 0.084539\n",
      "Epoch 128\n",
      "\n",
      "LOSS: 0.01354680, TIME: 5788.0s, psnr : 19.178580, mae : 0.084663\n",
      "Epoch 129\n",
      "\n",
      "LOSS: 0.01354770, TIME: 5833.2s, psnr : 19.181016, mae : 0.084645\n",
      "Epoch 130\n",
      "\n",
      "LOSS: 0.01349460, TIME: 5878.4s, psnr : 19.191542, mae : 0.084499\n",
      "Epoch 131\n",
      "\n",
      "LOSS: 0.01349499, TIME: 5923.6s, psnr : 19.190922, mae : 0.084496\n",
      "Epoch 132\n",
      "\n",
      "LOSS: 0.01349540, TIME: 5968.8s, psnr : 19.192476, mae : 0.084483\n",
      "Epoch 133\n",
      "\n",
      "LOSS: 0.01349444, TIME: 6014.1s, psnr : 19.193087, mae : 0.084485\n",
      "Epoch 134\n",
      "\n",
      "LOSS: 0.01348528, TIME: 6059.4s, psnr : 19.195032, mae : 0.084440\n",
      "Epoch 135\n",
      "\n",
      "LOSS: 0.01348621, TIME: 6104.6s, psnr : 19.194976, mae : 0.084463\n",
      "Epoch 136\n",
      "\n",
      "LOSS: 0.01346391, TIME: 6150.0s, psnr : 19.199632, mae : 0.084396\n",
      "Epoch 137\n",
      "\n",
      "LOSS: 0.01348738, TIME: 6195.2s, psnr : 19.196730, mae : 0.084466\n",
      "Epoch 138\n",
      "\n",
      "LOSS: 0.01349066, TIME: 6240.4s, psnr : 19.194410, mae : 0.084445\n",
      "Epoch 139\n",
      "\n",
      "LOSS: 0.01347035, TIME: 6285.6s, psnr : 19.199690, mae : 0.084388\n",
      "Epoch 140\n",
      "\n",
      "LOSS: 0.01347314, TIME: 6330.4s, psnr : 19.198284, mae : 0.084442\n",
      "Epoch 141\n",
      "\n",
      "LOSS: 0.01348643, TIME: 6375.6s, psnr : 19.198400, mae : 0.084414\n",
      "Epoch 142\n",
      "\n",
      "LOSS: 0.01347811, TIME: 6420.8s, psnr : 19.198341, mae : 0.084438\n",
      "Epoch 143\n",
      "\n",
      "LOSS: 0.01346374, TIME: 6466.1s, psnr : 19.203073, mae : 0.084361\n",
      "Epoch 144\n",
      "\n",
      "LOSS: 0.01346052, TIME: 6511.2s, psnr : 19.203426, mae : 0.084361\n",
      "Epoch 145\n",
      "\n",
      "LOSS: 0.01346336, TIME: 6556.5s, psnr : 19.202407, mae : 0.084372\n",
      "Epoch 146\n",
      "\n",
      "LOSS: 0.01345770, TIME: 6601.7s, psnr : 19.204201, mae : 0.084357\n",
      "Epoch 147\n",
      "\n",
      "LOSS: 0.01346128, TIME: 6647.0s, psnr : 19.203950, mae : 0.084364\n",
      "Epoch 148\n",
      "\n",
      "LOSS: 0.01345648, TIME: 6692.3s, psnr : 19.205204, mae : 0.084346\n",
      "Epoch 149\n",
      "\n",
      "LOSS: 0.01344914, TIME: 6737.4s, psnr : 19.206641, mae : 0.084335\n",
      "Epoch 150\n",
      "\n",
      "LOSS: 0.01343978, TIME: 6782.6s, psnr : 19.208555, mae : 0.084309\n",
      "Epoch 151\n",
      "\n",
      "LOSS: 0.01345313, TIME: 6827.8s, psnr : 19.207315, mae : 0.084334\n",
      "Epoch 152\n",
      "\n",
      "LOSS: 0.01344697, TIME: 6873.1s, psnr : 19.207943, mae : 0.084308\n",
      "Epoch 153\n",
      "\n",
      "LOSS: 0.01345869, TIME: 6918.2s, psnr : 19.205651, mae : 0.084350\n",
      "Epoch 154\n",
      "\n",
      "LOSS: 0.01344114, TIME: 6963.3s, psnr : 19.209184, mae : 0.084290\n",
      "Epoch 155\n",
      "\n",
      "LOSS: 0.01341820, TIME: 7008.6s, psnr : 19.214633, mae : 0.084234\n",
      "Epoch 156\n",
      "\n",
      "LOSS: 0.01344288, TIME: 7053.8s, psnr : 19.210002, mae : 0.084286\n",
      "Epoch 157\n",
      "\n",
      "LOSS: 0.01344341, TIME: 7099.1s, psnr : 19.209283, mae : 0.084328\n",
      "Epoch 158\n",
      "\n",
      "LOSS: 0.01343765, TIME: 7144.3s, psnr : 19.211973, mae : 0.084264\n",
      "Epoch 159\n",
      "\n",
      "LOSS: 0.01344470, TIME: 7189.5s, psnr : 19.211473, mae : 0.084279\n",
      "Epoch 160\n",
      "\n",
      "LOSS: 0.01341903, TIME: 7234.8s, psnr : 19.217354, mae : 0.084215\n",
      "Epoch 161\n",
      "\n",
      "LOSS: 0.01342643, TIME: 7279.9s, psnr : 19.215128, mae : 0.084231\n",
      "Epoch 162\n",
      "\n",
      "LOSS: 0.01340960, TIME: 7325.2s, psnr : 19.220897, mae : 0.084167\n",
      "Epoch 163\n",
      "\n",
      "LOSS: 0.01342655, TIME: 7370.4s, psnr : 19.216092, mae : 0.084226\n",
      "Epoch 164\n",
      "\n",
      "LOSS: 0.01341744, TIME: 7415.7s, psnr : 19.217332, mae : 0.084207\n",
      "Epoch 165\n",
      "\n",
      "LOSS: 0.01341720, TIME: 7460.3s, psnr : 19.220277, mae : 0.084169\n",
      "Epoch 166\n",
      "\n",
      "LOSS: 0.01342969, TIME: 7505.5s, psnr : 19.216792, mae : 0.084223\n",
      "Epoch 167\n",
      "\n",
      "LOSS: 0.01341480, TIME: 7550.7s, psnr : 19.218175, mae : 0.084175\n",
      "Epoch 168\n",
      "\n",
      "LOSS: 0.01341993, TIME: 7595.8s, psnr : 19.218045, mae : 0.084204\n",
      "Epoch 169\n",
      "\n",
      "LOSS: 0.01339826, TIME: 7641.1s, psnr : 19.224333, mae : 0.084139\n",
      "Epoch 170\n",
      "\n",
      "LOSS: 0.01339865, TIME: 7686.4s, psnr : 19.224185, mae : 0.084119\n",
      "Epoch 171\n",
      "\n",
      "LOSS: 0.01339128, TIME: 7731.5s, psnr : 19.226885, mae : 0.084109\n",
      "Epoch 172\n",
      "\n",
      "LOSS: 0.01339938, TIME: 7776.7s, psnr : 19.223222, mae : 0.084139\n",
      "Epoch 173\n",
      "\n",
      "LOSS: 0.01338109, TIME: 7821.9s, psnr : 19.229163, mae : 0.084055\n",
      "Epoch 174\n",
      "\n",
      "LOSS: 0.01337272, TIME: 7867.1s, psnr : 19.231905, mae : 0.084043\n",
      "Epoch 175\n",
      "\n",
      "LOSS: 0.01338697, TIME: 7912.2s, psnr : 19.227831, mae : 0.084094\n",
      "Epoch 176\n",
      "\n",
      "LOSS: 0.01339621, TIME: 7957.4s, psnr : 19.226799, mae : 0.084108\n",
      "Epoch 177\n",
      "\n",
      "LOSS: 0.01338687, TIME: 8002.6s, psnr : 19.229759, mae : 0.084080\n",
      "Epoch 178\n",
      "\n",
      "LOSS: 0.01341532, TIME: 8047.9s, psnr : 19.222742, mae : 0.084150\n",
      "Epoch 179\n",
      "\n",
      "LOSS: 0.01337632, TIME: 8093.1s, psnr : 19.231328, mae : 0.084047\n",
      "Epoch 180\n",
      "\n",
      "LOSS: 0.01337494, TIME: 8138.4s, psnr : 19.231607, mae : 0.084064\n",
      "Epoch 181\n",
      "\n",
      "LOSS: 0.01339114, TIME: 8183.7s, psnr : 19.228282, mae : 0.084082\n",
      "Epoch 182\n",
      "\n",
      "LOSS: 0.01337499, TIME: 8228.8s, psnr : 19.233085, mae : 0.084062\n",
      "Epoch 183\n",
      "\n",
      "LOSS: 0.01340051, TIME: 8273.9s, psnr : 19.227361, mae : 0.084089\n",
      "Epoch 184\n",
      "\n",
      "LOSS: 0.01335396, TIME: 8319.2s, psnr : 19.237666, mae : 0.083969\n",
      "Epoch 185\n",
      "\n",
      "LOSS: 0.01339966, TIME: 8364.4s, psnr : 19.222704, mae : 0.084145\n",
      "Epoch 186\n",
      "\n",
      "LOSS: 0.01336242, TIME: 8409.6s, psnr : 19.238458, mae : 0.083964\n",
      "Epoch 187\n",
      "\n",
      "LOSS: 0.01336450, TIME: 8454.8s, psnr : 19.235625, mae : 0.083991\n",
      "Epoch 188\n",
      "\n",
      "LOSS: 0.01335246, TIME: 8500.0s, psnr : 19.239234, mae : 0.083973\n",
      "Epoch 189\n",
      "\n",
      "LOSS: 0.01335701, TIME: 8545.3s, psnr : 19.237935, mae : 0.083973\n",
      "Epoch 190\n",
      "\n",
      "LOSS: 0.01336516, TIME: 8590.5s, psnr : 19.236102, mae : 0.083996\n",
      "Epoch 191\n",
      "\n",
      "LOSS: 0.01335617, TIME: 8635.6s, psnr : 19.238831, mae : 0.083961\n",
      "Epoch 192\n",
      "\n",
      "LOSS: 0.01334338, TIME: 8680.7s, psnr : 19.240824, mae : 0.083942\n",
      "Epoch 193\n",
      "\n",
      "LOSS: 0.01334019, TIME: 8726.0s, psnr : 19.241913, mae : 0.083917\n",
      "Epoch 194\n",
      "\n",
      "LOSS: 0.01334772, TIME: 8771.3s, psnr : 19.241912, mae : 0.083949\n",
      "Epoch 195\n",
      "\n",
      "LOSS: 0.01335296, TIME: 8816.5s, psnr : 19.239886, mae : 0.083930\n",
      "Epoch 196\n",
      "\n",
      "LOSS: 0.01335805, TIME: 8861.7s, psnr : 19.238759, mae : 0.083978\n",
      "Epoch 197\n",
      "\n",
      "LOSS: 0.01335843, TIME: 8906.9s, psnr : 19.240444, mae : 0.083924\n",
      "Epoch 198\n",
      "\n",
      "LOSS: 0.01333832, TIME: 8952.1s, psnr : 19.244558, mae : 0.083919\n",
      "Epoch 199\n",
      "\n",
      "LOSS: 0.01332220, TIME: 8997.3s, psnr : 19.247939, mae : 0.083845\n",
      "Epoch 200\n",
      "\n",
      "LOSS: 0.01334653, TIME: 9042.6s, psnr : 19.241259, mae : 0.083916\n",
      "Epoch 201\n",
      "\n",
      "LOSS: 0.01334123, TIME: 9087.8s, psnr : 19.244544, mae : 0.083902\n",
      "Epoch 202\n",
      "\n",
      "LOSS: 0.01334144, TIME: 9133.0s, psnr : 19.243064, mae : 0.083923\n",
      "Epoch 203\n",
      "\n",
      "LOSS: 0.01336301, TIME: 9178.2s, psnr : 19.238759, mae : 0.083988\n",
      "Epoch 204\n",
      "\n",
      "LOSS: 0.01333642, TIME: 9223.5s, psnr : 19.245943, mae : 0.083891\n",
      "Epoch 205\n",
      "\n",
      "LOSS: 0.01333436, TIME: 9268.7s, psnr : 19.247284, mae : 0.083880\n",
      "Epoch 206\n",
      "\n",
      "LOSS: 0.01333200, TIME: 9313.9s, psnr : 19.247574, mae : 0.083877\n",
      "Epoch 207\n",
      "\n",
      "LOSS: 0.01331932, TIME: 9359.1s, psnr : 19.249213, mae : 0.083829\n",
      "Epoch 208\n",
      "\n",
      "LOSS: 0.01332122, TIME: 9404.3s, psnr : 19.251072, mae : 0.083847\n",
      "Epoch 209\n",
      "\n",
      "LOSS: 0.01334702, TIME: 9449.5s, psnr : 19.243829, mae : 0.083916\n",
      "Epoch 210\n",
      "\n",
      "LOSS: 0.01332668, TIME: 9494.6s, psnr : 19.248632, mae : 0.083853\n",
      "Epoch 211\n",
      "\n",
      "LOSS: 0.01331219, TIME: 9539.9s, psnr : 19.251786, mae : 0.083822\n",
      "Epoch 212\n",
      "\n",
      "LOSS: 0.01331893, TIME: 9585.2s, psnr : 19.254107, mae : 0.083785\n",
      "Epoch 213\n",
      "\n",
      "LOSS: 0.01332102, TIME: 9630.5s, psnr : 19.249553, mae : 0.083856\n",
      "Epoch 214\n",
      "\n",
      "LOSS: 0.01333224, TIME: 9675.6s, psnr : 19.246955, mae : 0.083876\n",
      "Epoch 215\n",
      "\n",
      "LOSS: 0.01332793, TIME: 9720.7s, psnr : 19.249388, mae : 0.083857\n",
      "Epoch 216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOSS: 0.01330979, TIME: 9765.7s, psnr : 19.253590, mae : 0.083795\n",
      "Epoch 217\n",
      "\n",
      "LOSS: 0.01330706, TIME: 9810.9s, psnr : 19.257387, mae : 0.083757\n",
      "Epoch 218\n",
      "\n",
      "LOSS: 0.01332385, TIME: 9856.2s, psnr : 19.249494, mae : 0.083847\n",
      "Epoch 219\n",
      "\n",
      "LOSS: 0.01334162, TIME: 9901.4s, psnr : 19.247127, mae : 0.083869\n",
      "Epoch 220\n",
      "\n",
      "LOSS: 0.01330975, TIME: 9946.6s, psnr : 19.255549, mae : 0.083790\n",
      "Epoch 221\n",
      "\n",
      "LOSS: 0.01330039, TIME: 9991.8s, psnr : 19.256837, mae : 0.083775\n",
      "Epoch 222\n",
      "\n",
      "LOSS: 0.01330677, TIME: 10037.0s, psnr : 19.255413, mae : 0.083778\n",
      "Epoch 223\n",
      "\n",
      "LOSS: 0.01331215, TIME: 10082.3s, psnr : 19.254010, mae : 0.083816\n",
      "Epoch 224\n",
      "\n",
      "LOSS: 0.01330018, TIME: 10127.5s, psnr : 19.257882, mae : 0.083750\n",
      "Epoch 225\n",
      "\n",
      "LOSS: 0.01329556, TIME: 10172.7s, psnr : 19.259850, mae : 0.083733\n",
      "Epoch 226\n",
      "\n",
      "LOSS: 0.01329558, TIME: 10217.9s, psnr : 19.260375, mae : 0.083717\n",
      "Epoch 227\n",
      "\n",
      "LOSS: 0.01328950, TIME: 10263.1s, psnr : 19.260667, mae : 0.083735\n",
      "Epoch 228\n",
      "\n",
      "LOSS: 0.01327760, TIME: 10308.3s, psnr : 19.262723, mae : 0.083680\n",
      "Epoch 229\n",
      "\n",
      "LOSS: 0.01327831, TIME: 10353.6s, psnr : 19.264914, mae : 0.083674\n",
      "Epoch 230\n",
      "\n",
      "LOSS: 0.01329037, TIME: 10398.7s, psnr : 19.260176, mae : 0.083722\n",
      "Epoch 231\n",
      "\n",
      "LOSS: 0.01329882, TIME: 10444.1s, psnr : 19.259437, mae : 0.083762\n",
      "Epoch 232\n",
      "\n",
      "LOSS: 0.01328107, TIME: 10489.3s, psnr : 19.264405, mae : 0.083669\n",
      "Epoch 233\n",
      "\n",
      "LOSS: 0.01329061, TIME: 10534.5s, psnr : 19.261904, mae : 0.083707\n",
      "Epoch 234\n",
      "\n",
      "LOSS: 0.01328029, TIME: 10579.7s, psnr : 19.263597, mae : 0.083689\n",
      "Epoch 235\n",
      "\n",
      "LOSS: 0.01328212, TIME: 10624.9s, psnr : 19.264467, mae : 0.083669\n",
      "Epoch 236\n",
      "\n",
      "LOSS: 0.01327659, TIME: 10670.1s, psnr : 19.265510, mae : 0.083666\n",
      "Epoch 237\n",
      "\n",
      "LOSS: 0.01329248, TIME: 10715.4s, psnr : 19.261109, mae : 0.083736\n",
      "Epoch 238\n",
      "\n",
      "LOSS: 0.01326422, TIME: 10760.7s, psnr : 19.268558, mae : 0.083610\n",
      "Epoch 239\n",
      "\n",
      "LOSS: 0.01327056, TIME: 10805.9s, psnr : 19.267443, mae : 0.083634\n",
      "Epoch 240\n",
      "\n",
      "LOSS: 0.01327384, TIME: 10851.0s, psnr : 19.265956, mae : 0.083662\n",
      "Epoch 241\n",
      "\n",
      "LOSS: 0.01329614, TIME: 10896.2s, psnr : 19.262380, mae : 0.083713\n",
      "Epoch 242\n",
      "\n",
      "LOSS: 0.01328672, TIME: 10941.5s, psnr : 19.263831, mae : 0.083679\n",
      "Epoch 243\n",
      "\n",
      "LOSS: 0.01325963, TIME: 10986.6s, psnr : 19.269987, mae : 0.083618\n",
      "Epoch 244\n",
      "\n",
      "LOSS: 0.01326550, TIME: 11031.8s, psnr : 19.270237, mae : 0.083611\n",
      "Epoch 245\n",
      "\n",
      "LOSS: 0.01326949, TIME: 11076.9s, psnr : 19.268736, mae : 0.083625\n",
      "Epoch 246\n",
      "\n",
      "LOSS: 0.01331120, TIME: 11122.1s, psnr : 19.255358, mae : 0.083807\n",
      "Epoch 247\n",
      "\n",
      "LOSS: 0.01328242, TIME: 11167.3s, psnr : 19.264720, mae : 0.083664\n",
      "Epoch 248\n",
      "\n",
      "LOSS: 0.01327306, TIME: 11212.5s, psnr : 19.267180, mae : 0.083640\n",
      "Epoch 249\n",
      "\n",
      "LOSS: 0.01325481, TIME: 11257.7s, psnr : 19.272624, mae : 0.083585\n",
      "Epoch 250\n",
      "\n",
      "LOSS: 0.01327513, TIME: 11303.0s, psnr : 19.267659, mae : 0.083647\n",
      "Epoch 251\n",
      "\n",
      "LOSS: 0.01325422, TIME: 11348.1s, psnr : 19.273666, mae : 0.083556\n",
      "Epoch 252\n",
      "\n",
      "LOSS: 0.01328291, TIME: 11393.3s, psnr : 19.265039, mae : 0.083671\n",
      "Epoch 253\n",
      "\n",
      "LOSS: 0.01325907, TIME: 11438.4s, psnr : 19.272160, mae : 0.083595\n",
      "Epoch 254\n",
      "\n",
      "LOSS: 0.01324925, TIME: 11483.6s, psnr : 19.274940, mae : 0.083550\n",
      "Epoch 255\n",
      "\n",
      "LOSS: 0.01326525, TIME: 11528.8s, psnr : 19.270064, mae : 0.083617\n",
      "Epoch 256\n",
      "\n",
      "LOSS: 0.01328090, TIME: 11573.9s, psnr : 19.266392, mae : 0.083659\n",
      "Epoch 257\n",
      "\n",
      "LOSS: 0.01325320, TIME: 11619.2s, psnr : 19.273090, mae : 0.083586\n",
      "Epoch 258\n",
      "\n",
      "LOSS: 0.01324656, TIME: 11663.9s, psnr : 19.275345, mae : 0.083557\n",
      "Epoch 259\n",
      "\n",
      "LOSS: 0.01324092, TIME: 11708.6s, psnr : 19.275873, mae : 0.083541\n",
      "Epoch 260\n",
      "\n",
      "LOSS: 0.01324564, TIME: 11753.2s, psnr : 19.275070, mae : 0.083557\n",
      "Epoch 261\n",
      "\n",
      "LOSS: 0.01326034, TIME: 11797.8s, psnr : 19.274201, mae : 0.083570\n",
      "Epoch 262\n",
      "\n",
      "LOSS: 0.01324316, TIME: 11842.3s, psnr : 19.275457, mae : 0.083557\n",
      "Epoch 263\n",
      "\n",
      "LOSS: 0.01325004, TIME: 11886.8s, psnr : 19.273047, mae : 0.083559\n",
      "Epoch 264\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#test(test_loader, model, loss_fn)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 25\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_batches\n\u001b[1;32m     28\u001b[0m train_psnr \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_batches\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:264\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    261\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m    265\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model and output losses for 50 epochs\n",
    "epochs = 500\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    #test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe948806",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"ae_200.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e332163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
